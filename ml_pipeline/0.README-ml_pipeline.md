# GDM Pipeline Documentation

## 1. Overview

This module contains the Machine Learning pipeline for the PREGSAFE GDM Risk Prediction project. It is designed to be a single, unified workflow ("Master Pipeline") that handles:

1. **Folds Pass:** Cross-validation tuning, generation, and evaluation on 10 pre-processed data folds.
2. **Final Pass:** Training the final production model on the complete, filtered dataset.

## 2. Folder Structure

```ml_pipeline
ml_pipeline/
├── config/
│   └── config.yaml             # Central configuration file
├── data/
│   ├── preprocessed_folds/     # Contains Train_set_1.csv ... Train_set_10.csv
│   └── filtered_data/          # Contains Dataset_filtered.csv (Complete dataset)
├── logs/                       # Execution logs
├── outputs/                    # Generated artifacts (Models, Data, Reports, Plots)
├── scripts/
│   ├── run_pipeline.ps1        # Main execution script (Windows)
│   └── run_pipeline.sh         # Main execution script (Linux/Mac)
├── src/
│   ├── gdm_pipeline_common/    # Shared utilities and components
│   ├── gdm_pipeline_dimitris/  # Logic for Folds Pass (Tuning/Eval)
│   └── gdm_pipeline_final/     # Logic for Final Model Training
└── main.py                     # Main Python orchestrator
```

## 3. Setup & Installation

Ensure you have Python 3.10+ installed.

```bash
# Install the pipeline module in editable mode
pip install -e .
```

## 4. Execution

### **Windows**

Use the PowerShell script `scripts/run_pipeline.ps1`.

**Standard Production Run:**
Runs baseline generation (no tuning) for folds and trains the final model.

```powershell
.\scripts\run_pipeline.ps1
```

**Full Tuning Run:**
Runs Optuna hyperparameter tuning for all folds (computationally expensive).

```powershell
.\scripts\run_pipeline.ps1 --tune
```

**Smoke Test:**
Runs a fast, minimal version of the pipeline (2 epochs, subset of data) to verify code integrity.

```powershell
.\scripts\run_pipeline.ps1 --smoke-test --tune
```

### **Linux / GCP**

Use the Bash script `scripts/run_pipeline.sh`.

**Standard Production Run:**

```bash
./scripts/run_pipeline.sh
```

**Full Tuning Run:**

```bash
./scripts/run_pipeline.sh --tune
```

**Smoke Test:**

```bash
./scripts/run_pipeline.sh --smoke-test --tune
```

## 5. Outputs

All results are saved in the `outputs/` directory.

* **`MASTER_RUN/FOLDS_PASS/`**: Contains a folder for each `Train_set_X`.
  * `synthetic_data_{model}.csv`: Generated synthetic data.
  * `balanced_dataset_{model}.csv`: Merged original + synthetic data (50/50 balance).
  * `fidelity_plots_{model}/`: PCA plots, Correlation Heatmaps, Feature Distributions.
  * `sdv_reports/`: Statistical quality metrics.
  * `optuna_plots/`: Hyperparameter tuning visualization (if `-Tune` used).
  * `{model}_synthesizer.pkl`: The trained synthesizer model.

* **`MASTER_RUN/FINAL_PASS/`**: Contains the artifacts for the final production model.
  * `synthetic_data_CTGAN.csv`: Final synthetic dataset.
  * `CTGAN_synthesizer.pkl`: The final production synthesizer.

## 6. Key Configuration

Modify `config/config.yaml` to adjust:

* **Hyperparameters:** Search spaces for Optuna.
* **Epochs:** Training duration (`full_run` vs `smoke_test`).
* **Paths:** Input/Output directories.
